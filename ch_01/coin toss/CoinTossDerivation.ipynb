{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\"> Probability Matching </span>\n",
    "\"Probability Matching\" refers to a decision-making strategy where individuals choose options in proportion to their likelihood of ocurring, which mirrors the probability distribution of possible outcomes in a given situation.\n",
    "\n",
    "### <span style=\"color: green;\"> Tossing a Coin </span>\n",
    "In this Jupyter Notebook, we perform a simple game of betting on the outcome of tossing a biased coin. Using a learning agent, we gain an edge by basing the betting strategy on the previous outcome they observe. \n",
    "\n",
    "We record all the observed outcomes and randomly choose from the set of all previous outcomes. The bias is reflected in the number of times the agent randomly bets on heads as compared to tails.\n",
    "\n",
    "The agent can simply do better by simply betting on the most likely outcome as derived from past results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "from collections import Counter\n",
    "\n",
    "# importing required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a random number generator object\n",
    "rng = default_rng(seed=100)\n",
    "\n",
    "# defining the state space\n",
    "state_space = [1, 1, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the epoch function\n",
    "def epoch(n):\n",
    "\n",
    "    # total reward and action space\n",
    "    total_reward = 0\n",
    "    action_space = [0, 1]\n",
    "\n",
    "    # a for loop for n iterations\n",
    "    for _ in range(n):\n",
    "\n",
    "        # stores a dictionary of 1 and 0 occurrences\n",
    "        frequency = Counter(action_space)\n",
    "\n",
    "        # most chosen action and a coin toss\n",
    "        action_chosen = frequency.most_common()[0][0]\n",
    "        random_coin_toss = rng.choice(state_space)\n",
    "\n",
    "        # appending the total reward\n",
    "        if action_chosen == random_coin_toss:\n",
    "            total_reward += 1\n",
    "\n",
    "        # update of action space with highest frequency\n",
    "        action_space.append(random_coin_toss)\n",
    "\n",
    "    # returning the total reward\n",
    "    return total_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple sequences of bets in a numpy array\n",
    "rl = np.array([epoch(100) for _ in range(250)])\n",
    "\n",
    "# selecting the first ten elements\n",
    "print(\"First Ten Elements: \", rl[:10])\n",
    "\n",
    "# printing out the mean\n",
    "print(\"The Mean: \", rl.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing a list of iterations\n",
    "iterations = []\n",
    "for i in range(1, 251):\n",
    "    iterations.append(i)\n",
    "\n",
    "# plotting the graph\n",
    "plt.plot(iterations, rl)\n",
    "plt.axhline(y=rl.mean(), color=\"r\", linestyle=\"--\", label=\"Mean Reward\")\n",
    "plt.title(\"The Total Reward over each Iteration\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.legend()\n",
    "plt.savefig(\"C:\\GitHub\\ReinforcementFinance\\ch_01\\plots\\ProbabilityMatching.png\")\n",
    "\n",
    "# displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the different state spaces\n",
    "state_spaces = [[0, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 1, 0, 0, 0], [1, 1, 1, 0, 0], [1, 1, 1, 1, 0], [1, 1, 1, 1, 1]]\n",
    "\n",
    "# instantiating a random number generator object\n",
    "rng = default_rng(seed=100)\n",
    "\n",
    "# for loop of the states\n",
    "for state in state_spaces:\n",
    "\n",
    "    # defining the epoch function\n",
    "    def epoch(n):\n",
    "\n",
    "        # total reward and action space\n",
    "        total_reward = 0\n",
    "        action_space = [0, 1]\n",
    "\n",
    "        # a for loop for n iterations\n",
    "        for _ in range(n):\n",
    "\n",
    "            # stores a dictionary of 1 and 0 occurrences\n",
    "            frequency = Counter(action_space)\n",
    "\n",
    "            # most chosen action and a coin toss\n",
    "            action_chosen = frequency.most_common()[0][0]\n",
    "            random_coin_toss = rng.choice(state)\n",
    "\n",
    "            # appending the total reward\n",
    "            if action_chosen == random_coin_toss:\n",
    "                total_reward += 1\n",
    "\n",
    "            # update of action space with highest frequency\n",
    "            action_space.append(random_coin_toss)\n",
    "\n",
    "        # returning the total reward\n",
    "        return total_reward\n",
    "    \n",
    "    # multiple sequences of bets in a numpy array\n",
    "    rl = np.array([epoch(100) for _ in range(250)])\n",
    "\n",
    "    # storing a list of iterations\n",
    "    iterations = []\n",
    "    for i in range(1, 251):\n",
    "        iterations.append(i)\n",
    "\n",
    "    # plotting the graph\n",
    "    plt.plot(iterations, rl)\n",
    "    print(\"Mean Reward is: \", rl.mean(), \"\\n\")\n",
    "    plt.axhline(y=rl.mean(), color=\"r\", linestyle=\"--\", label=\"Mean Reward\")\n",
    "    plt.title(\"The Total Reward over each Iteration\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.legend()\n",
    "\n",
    "    # setting up the title\n",
    "    plt.title(f\"Total Reward of State Space {state}\")\n",
    "\n",
    "    # saving the figure\n",
    "    plt.savefig(f\"C:\\GitHub\\ReinforcementFinance\\ch_01\\plots\\RewardStateSpace{state}.png\")\n",
    "\n",
    "    # displaying the plot\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financeEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
